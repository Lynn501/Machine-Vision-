{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "KEUIQRs4ugzw"
      },
      "id": "KEUIQRs4ugzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = r'/content/drive/MyDrive/cars_tanks/train'\n",
        "test_dir = r'/content/drive/MyDrive/cars_tanks/test'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNE-nS5CvfNX",
        "outputId": "839af7b7-32cf-465d-d753-54150585002e"
      },
      "id": "kNE-nS5CvfNX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
        "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
        "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "pXEXsERHulcL"
      },
      "id": "pXEXsERHulcL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n",
        "                 groups=1, width_per_group=64):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        width = int(out_channel * (width_per_group / 64.)) * groups\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,\n",
        "                               kernel_size=1, stride=1, bias=False)  # squeeze channels\n",
        "        self.bn1 = nn.BatchNorm2d(width)\n",
        "        # -----------------------------------------\n",
        "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,\n",
        "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(width)\n",
        "        # -----------------------------------------\n",
        "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,\n",
        "                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "A51_Qkayut_a"
      },
      "id": "A51_Qkayut_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxSDcJ9tuq46"
      },
      "id": "IxSDcJ9tuq46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tankCarCls(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 blocks_num,\n",
        "                 num_classes=1000,\n",
        "                 include_top=True,\n",
        "                 groups=1,\n",
        "                 width_per_group=64):\n",
        "        super(tankCarCls, self).__init__()\n",
        "        self.include_top = include_top\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.groups = groups\n",
        "        self.width_per_group = width_per_group\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
        "                               padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        if self.include_top:\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n",
        "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel,\n",
        "                            channel,\n",
        "                            downsample=downsample,\n",
        "                            stride=stride,\n",
        "                            groups=self.groups,\n",
        "                            width_per_group=self.width_per_group))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel,\n",
        "                                channel,\n",
        "                                groups=self.groups,\n",
        "                                width_per_group=self.width_per_group))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.channelAttention(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.include_top:\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uAv96sxEuydN"
      },
      "id": "uAv96sxEuydN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tankCarCls_v0(num_classes=2, include_top=True):\n",
        "    return tankCarCls(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)"
      ],
      "metadata": {
        "id": "w-d8ev-0u5JN"
      },
      "id": "w-d8ev-0u5JN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    import os\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # 下面老是报错 shape 不一致\n",
        "\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    # device = torch.device(\"cpu\")\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    data_transform = {\n",
        "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "        \"val\": transforms.Compose([transforms.Resize(256),\n",
        "                                   transforms.CenterCrop(224),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
        "    train_dataset = datasets.ImageFolder(root=os.path.join(\"/content/drive/MyDrive/cars_tanks/train\"),\n",
        "                                         transform=data_transform[\"train\"])\n",
        "    train_num = len(train_dataset)\n",
        "\n",
        "\n",
        "    flower_list = train_dataset.class_to_idx\n",
        "    cla_dict = dict((val, key) for key, val in flower_list.items())\n",
        "    # write dict into json file\n",
        "    json_str = json.dumps(cla_dict, indent=2)\n",
        "    with open('class_indices.json', 'w') as json_file:\n",
        "        json_file.write(json_str)\n",
        "\n",
        "    batch_size = 4\n",
        "    nw = 0  # number of workers\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=nw)\n",
        "\n",
        "    validate_dataset = datasets.ImageFolder(root=os.path.join(\"/content/drive/MyDrive/cars_tanks/train\"),\n",
        "                                            transform=data_transform[\"val\"])\n",
        "    val_num = len(validate_dataset)\n",
        "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
        "                                                  batch_size=batch_size, shuffle=False,\n",
        "                                                  num_workers=nw)\n",
        "\n",
        "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
        "                                                                           val_num))\n",
        "\n",
        "    net = tankCarCls_v0()\n",
        "\n",
        "    # change fc layer structure\n",
        "    in_channel = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_channel, 2)\n",
        "    net.to(device)\n",
        "\n",
        "    # define loss function\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    # construct an optimizer\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(params, lr=0.0001)\n",
        "\n",
        "    epochs = 30\n",
        "    best_acc = 0.0\n",
        "    save_path = './tankCarCls_v1.pth'\n",
        "    train_steps = len(train_loader)\n",
        "    torch.cuda.empty_cache()\n",
        "    writer = SummaryWriter(\"logs\")\n",
        "    for epoch in range(epochs):\n",
        "        # train\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            logits = net(images.to(device))\n",
        "            loss = loss_function(logits, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
        "                                                                     epochs,\n",
        "                                                                     loss)\n",
        "\n",
        "        # validate\n",
        "        net.eval()\n",
        "        acc = 0.0  # accumulate accurate number / epoch\n",
        "        TP = 0.0\n",
        "        FP = 0.0\n",
        "        FN = 0.0\n",
        "        TN = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                outputs = net(val_images.to(device))\n",
        "                # loss = loss_function(outputs, test_labels)\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "\n",
        "\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "\n",
        "                TP += (torch.eq(predict_y, val_labels.to(device)) & torch.eq(predict_y, 0)).sum().item()\n",
        "\n",
        "                # 10\n",
        "                FP += (torch.eq(predict_y, 1) & torch.eq(val_labels.to(device), 0)).sum().item()\n",
        "                # 01\n",
        "                FN += (torch.eq(predict_y, 0) & torch.eq(val_labels.to(device), 1)).sum().item()\n",
        "                # 11\n",
        "                TN += (torch.eq(predict_y, 1) & torch.eq(val_labels.to(device), 1)).sum().item()\n",
        "\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
        "                                                           epochs)\n",
        "\n",
        "        val_accurate = acc / val_num  #（TP+TN）/（TP+FP+TN+FN）\n",
        "        # Precision=TP/（TP+FP）\n",
        "        Precision = TP /(TP + FP)\n",
        "        Recall = TP / (TP + FN)\n",
        "        # Precision-recall\n",
        "        # Confusion matrix\n",
        "        F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "        Sensitivity = TP / (TP + FN)\n",
        "        Specificity = TN / (TN + FP)\n",
        "        print('[epoch %d] loss: %.3f  accuracy: %.3f  Precision: %.3f  Recall: %.3f  F1: %3f  Sensitivity: %.3f  Specificity: %.3f'   %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate,Precision,Recall, F1, Sensitivity, Specificity))\n",
        "\n",
        "        writer.add_scalar(\"Accuracy-epoch\", val_accurate, epoch+1)\n",
        "        writer.add_scalar(\"loss-epoch\", running_loss, epoch+1)\n",
        "        writer.add_scalar(\"Precision-epoch\", Precision, epoch+1)\n",
        "        writer.add_scalar(\"Recall-epoch\", Recall, epoch+1)\n",
        "        writer.add_scalar(\"Precision-Recall\", Precision, Recall)\n",
        "        writer.add_scalar(\"F1-epoch\", F1, epoch + 1)\n",
        "        writer.add_scalar(\"Sensitivity-epoch\", Sensitivity, epoch + 1)\n",
        "        writer.add_scalar(\"Specificity-epoch\", Specificity, epoch + 1)\n",
        "        writer.add_scalar(\"Sensitivity-Specificity\", Sensitivity, Specificity)\n",
        "\n",
        "\n",
        "\n",
        "        if val_accurate > best_acc:\n",
        "            best_acc = val_accurate\n",
        "            torch.save(net.state_dict(), save_path)\n",
        "    writer.close()\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "id": "bb_hGutHu_qz"
      },
      "id": "bb_hGutHu_qz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddbdd0a",
      "metadata": {
        "id": "9ddbdd0a"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}